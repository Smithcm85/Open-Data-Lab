{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the spark environment\n",
    "import pyspark\n",
    "conf = pyspark.SparkConf().setAppName('odl').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "sqlc = pyspark.sql.SQLContext(sc)\n",
    "from sagemaker import get_execution_role\n",
    "from pyspark.sql.types import LongType, StringType, StructField, StructType, BooleanType, ArrayType, IntegerType\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"admissions.csv\"\n",
    "df = sqlc.read.format(\"csv\")\\\n",
    "  .option(\"header\",\"true\")\\\n",
    "  .option(\"inferSchema\", \"true\")\\\n",
    "  .load(dataPath)\n",
    "df = df.withColumnRenamed(\"Serial No.\", \"SerialNumber\")\n",
    "df = df.withColumnRenamed(\"GRE Score\", \"GRE\")\n",
    "df = df.withColumnRenamed(\"TOEFL Score\", \"TOEFL\")\n",
    "df = df.withColumnRenamed(\"University Rating\", \"UniversityRating\")\n",
    "df = df.withColumnRenamed(\"LOR \", \"LOR\")\n",
    "df = df.withColumnRenamed(\"Chance of Admit \", \"ChanceOfAdmit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing data into parquet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquetPath = '/home/ec2-user/SageMaker/khg8mh/parquet_data'\n",
    "df.write.parquet(parquetPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting data back from parquet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlc.read.parquet(parquetPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLlib based analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre-processing before building a model\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['GRE','TOEFL','UniversityRating','SOP','LOR','CGPA','Research'], outputCol=\"features\")\n",
    "stages = [assembler]\n",
    "\n",
    "label_stringIdx = StringIndexer(inputCol=\"ChanceOfAdmit\", outputCol=\"label\")\n",
    "stages += [label_stringIdx]\n",
    "\n",
    "partialPipeline = Pipeline().setStages(stages)\n",
    "pipelineModel = partialPipeline.fit(df)\n",
    "preppedDataDF = pipelineModel.transform(df)\n",
    "\n",
    "selectedcols = [\"label\", \"features\"] + df.columns\n",
    "dataset = preppedDataDF.select(selectedcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=1)\n",
    "\n",
    "# Train model with Training Data\n",
    "lrModel = lr.fit(trainingData)\n",
    "\n",
    "# Predict on testing data\n",
    "predictions = lrModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7448275862068966"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calulate area under ROC curve\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "\n",
    "# Area under ROC curve\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------------+---+-----+----------------+---+---+----+--------+-------------+--------------------+--------------------+----------+\n",
      "|label|            features|SerialNumber|GRE|TOEFL|UniversityRating|SOP|LOR|CGPA|Research|ChanceOfAdmit|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+------------+---+-----+----------------+---+---+----+--------+-------------+--------------------+--------------------+----------+\n",
      "|  0.0|[303.0,100.0,2.0,...|         353|303|  100|               2|3.0|3.5|8.06|       1|         0.64|[1.19266838068373...|[0.04329127798889...|       0.0|\n",
      "|  0.0|[312.0,98.0,1.0,3...|         294|312|   98|               1|3.5|3.0|8.18|       1|         0.64|[1.19639417643196...|[0.04340819283431...|       0.0|\n",
      "|  0.0|[312.0,105.0,2.0,...|         102|312|  105|               2|2.5|3.0|8.12|       0|         0.64|[1.20223204901295...|[0.04362361981858...|       0.0|\n",
      "|  0.0|[312.0,107.0,3.0,...|          21|312|  107|               3|3.0|2.0| 7.9|       1|         0.64|[1.19867242497532...|[0.04345485534958...|       0.0|\n",
      "|  0.0|[318.0,106.0,2.0,...|          91|318|  106|               2|4.0|4.0|7.92|       1|         0.64|[1.20103536006858...|[0.04348448577087...|       0.0|\n",
      "|  1.0|[305.0,107.0,2.0,...|         182|305|  107|               2|2.5|2.5|8.42|       0|         0.71|[1.20089641269456...|[0.04358484677686...|       0.0|\n",
      "|  1.0|[305.0,112.0,3.0,...|         300|305|  112|               3|3.0|3.5|8.65|       0|         0.71|[1.20297355575048...|[0.04358284598163...|       0.0|\n",
      "|  1.0|[309.0,105.0,5.0,...|         133|309|  105|               5|3.5|3.5|8.56|       0|         0.71|[1.19977660526958...|[0.04345804169552...|       0.0|\n",
      "|  1.0|[313.0,102.0,3.0,...|         266|313|  102|               3|2.5|2.5|8.68|       0|         0.71|[1.20234951190270...|[0.04360555748367...|       0.0|\n",
      "|  1.0|[316.0,100.0,2.0,...|         138|316|  100|               2|1.5|3.0|8.16|       1|         0.71|[1.19965226844564...|[0.04352008166102...|       0.0|\n",
      "|  2.0|[306.0,105.0,2.0,...|         271|306|  105|               2|2.5|3.0|8.22|       1|         0.72|[1.19702901903617...|[0.04341842133655...|       0.0|\n",
      "|  2.0|[309.0,108.0,3.0,...|         179|309|  108|               3|2.5|3.0|8.12|       0|         0.72|[1.20164573080157...|[0.04358465907610...|       0.0|\n",
      "|  2.0|[310.0,103.0,2.0,...|         371|310|  103|               2|2.5|2.5|8.24|       0|         0.72|[1.20076991573369...|[0.04359121520548...|       0.0|\n",
      "|  2.0|[315.0,110.0,2.0,...|         202|315|  110|               2|3.5|3.0|8.46|       1|         0.72|[1.20338446734150...|[0.04355659187682...|       0.0|\n",
      "|  2.0|[316.0,105.0,3.0,...|         247|316|  105|               3|3.0|3.5|8.73|       0|         0.72|[1.20492932557222...|[0.04364342755640...|       0.0|\n",
      "|  2.0|[320.0,110.0,2.0,...|         114|320|  110|               2|4.0|3.5|8.56|       0|         0.72|[1.20845305937971...|[0.04373417105525...|       0.0|\n",
      "|  3.0|[307.0,102.0,3.0,...|         180|307|  102|               3|3.0|3.0|8.27|       0|         0.73|[1.19817517443414...|[0.04348288543229...|       0.0|\n",
      "|  3.0|[312.0,107.0,4.0,...|         335|312|  107|               4|4.5|4.0|8.65|       1|         0.73|[1.19946256507610...|[0.04337223351523...|       0.0|\n",
      "|  3.0|[319.0,105.0,3.0,...|         382|319|  105|               3|3.0|3.5|8.67|       1|         0.73|[1.20324828594309...|[0.04353795290738...|       0.0|\n",
      "|  3.0|[323.0,107.0,3.0,...|         304|323|  107|               3|3.5|3.5|8.55|       1|         0.73|[1.20526201250373...|[0.04358194301427...|       0.0|\n",
      "+-----+--------------------+------------+---+-----+----------------+---+---+----+--------+-------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression_4457ad37a88cceda8ca1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[SerialNumber: int, GRE: int, TOEFL: int, UniversityRating: int, SOP: double, LOR: double, CGPA: double, Research: int, ChanceOfAdmit: double, features: vector, label: double]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ROC'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dislpay() function doesn't show output in jupyter notebook for some reason\n",
    "display(lrModel, preppedDataDF, 'ROC')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
